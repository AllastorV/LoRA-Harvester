"""
Ensemble Detector Demo and Comparison
Compares single model vs ensemble detection accuracy
"""

import cv2
import numpy as np
import sys
import os

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))


def compare_detectors(image_path: str = None):
    """Compare single model vs ensemble detection"""
    
    print("="*70)
    print("ü§ñ ENSEMBLE DETECTOR COMPARISON")
    print("="*70)
    print()
    
    # Create or load test image
    if image_path and os.path.exists(image_path):
        print(f"üì∑ Loading image: {image_path}")
        frame = cv2.imread(image_path)
    else:
        print("üì∑ Creating test image with multiple objects...")
        frame = create_test_image()
        cv2.imwrite('test_ensemble_image.jpg', frame)
        print("‚úÖ Test image saved: test_ensemble_image.jpg")
    
    print()
    print("-"*70)
    print("1Ô∏è‚É£  SINGLE MODEL DETECTION (YOLOv8 only)")
    print("-"*70)
    
    try:
        from src.core.detector import ObjectDetector
        
        detector_single = ObjectDetector(confidence=0.5)
        detections_single = detector_single.detect(frame)
        
        total_single = sum(len(detections_single[cat]) for cat in detections_single)
        print(f"‚úÖ Total detections: {total_single}")
        print(f"   üë§ Persons: {len(detections_single['person'])}")
        print(f"   üêæ Animals: {len(detections_single['animal'])}")
        print(f"   üì¶ Objects: {len(detections_single['object'])}")
        
        # Draw results
        frame_single = draw_detections(frame.copy(), detections_single, "YOLOv8 Only")
        cv2.imwrite('result_single_model.jpg', frame_single)
        print("üíæ Result saved: result_single_model.jpg")
        
    except Exception as e:
        print(f"‚ùå Single model error: {e}")
        return
    
    print()
    print("-"*70)
    print("2Ô∏è‚É£  ENSEMBLE DETECTION (YOLO + DETR + Faster R-CNN)")
    print("-"*70)
    
    try:
        from src.core.ensemble_detector import EnsembleDetector
        
        detector_ensemble = EnsembleDetector(
            models_to_use=['yolo', 'detr', 'fasterrcnn'],
            confidence_threshold=0.5,
            voting_threshold=2
        )
        
        detections_ensemble = detector_ensemble.detect(frame)
        
        total_ensemble = sum(len(detections_ensemble[cat]) for cat in detections_ensemble)
        print(f"‚úÖ Total detections: {total_ensemble}")
        print(f"   üë§ Persons: {len(detections_ensemble['person'])}")
        print(f"   üêæ Animals: {len(detections_ensemble['animal'])}")
        print(f"   üì¶ Objects: {len(detections_ensemble['object'])}")
        
        # Show which models agreed
        print()
        print("üó≥Ô∏è  Model Agreement Details:")
        for category in ['person', 'animal', 'object']:
            for det in detections_ensemble[category]:
                if 'models' in det:
                    print(f"   {category}: {det['class_name']} - {det['models']}")
        
        # Draw results
        frame_ensemble = draw_detections(frame.copy(), detections_ensemble, "Ensemble (3 Models)")
        cv2.imwrite('result_ensemble.jpg', frame_ensemble)
        print()
        print("üíæ Result saved: result_ensemble.jpg")
        
    except Exception as e:
        print(f"‚ùå Ensemble error: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print()
    print("="*70)
    print("üìä COMPARISON SUMMARY")
    print("="*70)
    print(f"Single Model:  {total_single} detections")
    print(f"Ensemble Mode: {total_ensemble} detections (consensus-based)")
    print()
    print("‚ú® Ensemble Benefits:")
    print("   ‚Ä¢ Reduced false positives (voting mechanism)")
    print("   ‚Ä¢ Higher confidence in detections")
    print("   ‚Ä¢ Better handling of difficult cases")
    print("   ‚Ä¢ Cross-validation between different architectures")
    print()
    print("‚ö° Trade-off:")
    print("   ‚Ä¢ ~2-3x slower than single model")
    print("   ‚Ä¢ But significantly more accurate")
    print("="*70)


def create_test_image():
    """Create a test image with various shapes"""
    width, height = 1920, 1080
    frame = np.ones((height, width, 3), dtype=np.uint8) * 240
    
    # Add some colored shapes to simulate objects
    # Circle (person-like)
    cv2.circle(frame, (400, 400), 150, (100, 150, 200), -1)
    cv2.circle(frame, (400, 300), 50, (80, 120, 180), -1)  # head
    
    # Rectangle (object-like)
    cv2.rectangle(frame, (1200, 600), (1500, 900), (150, 100, 180), -1)
    
    # Ellipse (animal-like)
    cv2.ellipse(frame, (800, 700), (200, 100), 0, 0, 360, (180, 150, 100), -1)
    
    # Add some text
    cv2.putText(frame, 'Test Scene for Detection', (50, 100), 
               cv2.FONT_HERSHEY_SIMPLEX, 2, (50, 50, 50), 3)
    
    return frame


def draw_detections(frame, detections, title):
    """Draw detection boxes on frame"""
    colors = {
        'person': (0, 255, 0),    # Green
        'animal': (255, 165, 0),  # Orange
        'object': (255, 0, 255)   # Magenta
    }
    
    for category, color in colors.items():
        for det in detections[category]:
            bbox = det['bbox']
            conf = det['confidence']
            
            # Draw box
            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 3)
            
            # Draw label
            label = f"{category}: {conf:.2f}"
            if 'models' in det:
                label += f" ({det['models']})"
            
            cv2.putText(frame, label, (bbox[0], bbox[1] - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    
    # Add title
    cv2.putText(frame, title, (20, 50),
               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)
    cv2.putText(frame, title, (20, 50),
               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)
    
    return frame


def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Compare single vs ensemble detection")
    parser.add_argument('-i', '--image', help='Input image path (optional)')
    args = parser.parse_args()
    
    compare_detectors(args.image)
    
    print()
    print("üéØ Next steps:")
    print("   1. Check the output images: result_single_model.jpg & result_ensemble.jpg")
    print("   2. Try with your own image: python ensemble_demo.py -i your_image.jpg")
    print("   3. Use ensemble in main app: Enable 'ü§ñ Ensemble Mode' checkbox")
    print()


if __name__ == "__main__":
    main()
